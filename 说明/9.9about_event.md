下面把你当前“记忆写入 → 与 event 关联 → 检索注入”的整条链路梳理一遍，并指出各个环节的关键细节与隐患（均定位到你代码里的具体位置）。

---

# 一、触发：什么时候会“批量抽取+写入记忆”

* 生成回复后，会判断是否触发“批量抽取记忆”。你现在有两套触发与水位机制并存：
  1. **按空闲/轮数的轻量判断** ：`idle_seconds >= 5*60` 或 `should_trigger_by_rounds(round_cap=10)`。如果触发，就做一轮“切分与抽取”并写库，最后把 `last_batch_msg_idx` 置为最新条目（仅用于下次“轮数”统计，不参与去重） 。
  2. **基于“水位”的旧方案** ：`persist_segments_except_last_with_wm` 会用 `processed_until_msg_idx` 作为“水位”，只写入 end_turn 大于水位的段，并推进水位；不过这条旧路径在你的“主聊天逻辑”里 **没有被调用** （属于备用函数） 。
* 聊天上下文里，取最近 k 轮对话用于 **生成回复** （和抽取触发无关）。k 由 `compute_adaptive_k` 动态决定：遇到一次“大停顿”后到现在的用户轮数，或最近用户轮数≥阈值；否则只取 1 轮。它只影响“生成阶段”的上下文长度，不直接影响抽取/写入逻辑 。

---

# 二、切分与抽取：LLM 输出如何被清洗

* `call_llm_segment_and_extract` 读取 `extract_prompt.txt`，把全量对话拼成 `"i. (role) content"` 的块丢给 LLM，要它返回 `{"segments":[{"memories":[{"content","importance"}], "end_turn":...}, ...]}`。函数随后对 JSON 做 **清洗/截断（≤100 字）**与**importance 归一化** ，且在“分数全一样或全很高”时会在批内做一次**线性重标定** 。
* 主流程会 **丢弃最后一段** （避免正在进行的话题被提前写库），只收集 `segs[:-1]` 里的记忆项进入后续写入流程 。
* 旧的“带水位”的写入函数也遵循“丢最后段+过滤 end_turn ≤ 水位”的规则（但目前未在主流程调用）。

---

# 三、写入数据库：你现在实际走的是“轻量新路径”

> 重点： **当前主路径不计算 embedding，直接写入** 。

* 在“主聊天逻辑”中，抽取后的 `raw_items` 会先转成 `MemoryUnit(content, importance)`（ **没有 embedding** ）。
* 然后做两级过滤：
  1. `MIN_IMPORTANCE = 0.30` 以下丢弃；
  2. 以 **content 精确匹配** 去重：既对比库内 `get_all()` 的内容集合，又在本批内做 `seen_in_batch` 去重（ **仅按字符串完全一致** ）。
* 通过过滤的条目逐条 `store.add(mu)` 入库。注意你的 `add` 会把 `embedding` 置空（NULL）时走 `COALESCE(EXCLUDED.embedding, memory.embedding)`，即 **不会帮你后来自动补 embedding** ；最终库里真的就是 NULL 向量 。
* 完成后更新 `last_batch_msg_idx = len(msgs)-1`，以便下次“按轮数”触发时只计算新增的用户轮数 。

> 对比：旧的 `persist_segments_except_last_with_wm` 写法在入库前**会调用 `embed_text(bgem3, f"passage:{c}")` 计算 embedding** 并随条目一起写库，同时推进“水位”。但这条函数在主流程中 **未被调用** ，属于“更严格但未启用”的版本 。

**直接后果：**

* 你的检索函数 `search_by_embedding` 明确 `WHERE embedding IS NOT NULL`，所以 **本轮刚写入、embedding 为空的记忆在随后的检索中是“不可见”的** （直到你另有补齐流程；当前代码里没有）。
* 同理，事件质心（centroid）的更新若依赖单条记忆的 embedding，就会退化为使用 **turn 级向量** （见下文），导致事件语义中心可能偏向本轮 query，而不是多条记忆的均值方向。

---

# 四、与 Event 的关联：当前“快速绑定”与“草稿路由”并存，但只启用前者

## A. 快速绑定（ **现在在用** ）

* `assign_event_for_units(store, turn_text, turn_emb, units)`：
  1. 只在**最近 3 天**的事件里找相似度最高的一个（用  **turn_emb 与 event.centroid 的余弦** ）。若 `sim >= 0.72`，沿用；否则创建新事件，`centroid` 初始用  **turn_emb** 。标题由 `suggest_event_title_simple` 基于 turn_text + 记忆文本关键词生成 。
  2. 绑定所有 `units` 到该事件，并调用 `touch_event_with_embedding(ev_id, seed)` 以 EMA 刷新质心（`alpha=0.7`，即 **旧质心占 70%，新向量占 30%** ）。这里的 `seed` 使用 `mu.embedding or turn_emb`——**因为你当前写入没算 embedding，大概率走 turn_emb**  。
* 这套绑定在主流程里 **确实被调用** （仅对“本轮 accepted”）。

**影响与限制：**

* 只看“近 3 天”可能导致 **复用不到更早的同主题事件** ，从而频繁创建“近似重复”事件（尤其你工作主题跨度超过 3 天时）。
* 质心更新主要吃 **turn_emb** 而非  **记忆 embedding** ，在一个 turn 内多条记忆差异较大时，事件语义中心会被“问题向量”主导，而不是成员记忆的均值（精度受限）。

## B. 草稿路由（ **代码已就绪，但主流程未接入** ）

* `EventDraftManager.route_event_memory` 的“三步路由”：
  1. 先与**活跃草稿池**匹配（阈值 `0.68`），近似即把同一主题的连续回合都聚到一个 draft；
  2. 不合并草稿，再尝试 **历史事件** （通过 `search_events_by_embedding`，阈值 `0.82`）链接到旧事件；
  3. 都不满足则 **新建草稿** ，暂不落库；
  4. 需要时调用 `finalize_draft()` 才会真正创建事件并批量绑定成员记忆（质心用成员 embedding 的均值/EMA）  。
* 这条线能更好地解决“跨回合同主题聚拢、等主题稳定再落库”的需求，但 **目前主流程没有调用** （`assign_event_for_units` 仍是实际在跑的那条）。

---

# 五、检索与注入：如何把记忆喂给 LLM

* 用户发问时计算 `prompt_embedding = embed_text(bgem3, f"query:{prompt}")`；检索器从 `MemoryStore` 里按向量相似度取 top-k（只会命中 **embedding 非空** 的条目），随后 **把命中的记忆的“同事件兄弟”也扩展进来** （`get_event_context`）用于“提示注入” 。
* 注入时，`llm_clients._prepare_messages_with_memories` 会把“Relevant Memories”拼成条目列表塞到 **system prompt** 区块里，配合最近 k 轮对话一起送入模型生成回答 。

---

# 六、你看到的“重复记忆”的来源（结合代码逻辑）

* **批间去重仅按“content 的精确字符串相等”** ：任何轻微变化（标点、同义改写、数字格式）都可能绕过去重，从而反复入库（比如“林深，28岁，女性” vs “用户名为林深，女性，28岁”）。
* 若你改回“旧水位方案”，可以借 `end_turn > 水位` 在**段级**避免重复处理，但你目前主路径并未使用这套水位过滤（所以主要靠“字符串等值”去重）。
* 另外，`get_all()` 再做集合对比用于去重是 **在线全量扫描** ，当数据规模变大时会有性能与一致性风险（但这是优化层面，非逻辑错误）。

---

# 七、关键结论（浓缩版）

1. **当前主写入路径不算 embedding** ，导致 **新记忆短期不可检索** （`WHERE embedding IS NOT NULL`），且事件质心主要受 turn_emb 影响，不够稳定与精确  。
2. **Event 复用只看近 3 天**且阈值 0.72，易产生主题相近但跨天的“新事件泛滥” 。
3. **去重只做字符串等值** ，对“同义改写/空格标点差异”不鲁棒，导致你观察到的重复入库 。
4. 你代码中同时存在**“快速绑定” **与** “草稿路由”**两套 event 关联方案，但实际只启用了前者；后者能更好地聚合跨回合主题并在**落库时**用成员 embedding 稳定质心（建议后续切换/接入） 。
5. 旧的**水位式持久化**函数能避免重复段被反复处理，但目前未接入主流程（仅用作工具函数）。

---

要我接着把“快速修复清单”（最小改动把 embedding 补齐、把 event 复用窗口从 3 天扩到 N 天、加规范化去重、或把主流程切到草稿路由）也直接改成一段 patch 建议吗？
